path:
  data_dir: datasets
  #feat_dir: feats
  feat_dir: feats_mel

train:
  autoencoder_learning_rate: 0.001

  # for classifier
  # additional 2 convolution layer
  # additional 3 dense layer
  # adam optimizer
  classifier_train_epoch_num: 10000
  # exponential decay scheduler
  classifier_initial_learning_rate: 0.00001
  classifier_end_learning_rate: 0.000001
  classifier_lr_decay_rate: 0.96
  classifier_batch_size: 6  # number of data participating in actual training : batch_size * 11
  classifier_valid_interval: 1000
  classifier_chkpt_interval: 3000

model:
  embed_dims: 512


audio:
  sampling_rate: 16000
  rescaling_max: 0.999
  n_fft: 1024
  #time_length: 63
  time_length: 101
  hop_length: 160
  win_length: 400
  min_level_db: -100.0
  ref_level_db: 20.0
  fmin: 125
  fmax: 7600
  n_mels: 80
  n_mfcc: 40
